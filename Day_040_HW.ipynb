{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "使用 Sklearn 中的 Lasso, Ridge 模型，來訓練各種資料集，務必了解送進去模型訓練的**資料型態**為何，也請了解模型中各項參數的意義。\n",
    "\n",
    "機器學習的模型非常多種，但要訓練的資料多半有固定的格式，確保你了解訓練資料的格式為何，這樣在應用新模型時，就能夠最快的上手開始訓練！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習時間\n",
    "試著使用 sklearn datasets 的其他資料集 (boston, ...)，來訓練自己的線性迴歸模型，並加上適當的正則化來觀察訓練情形。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from sklearn import datasets , linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step1] Data loading, preprocessing, and exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': 'D:\\\\Anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\boston_house_prices.csv'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 載入酒類資料集, 並觀察原始資料\n",
    "boston = datasets.load_boston()\n",
    "boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  target  \n",
       "0       15.3  396.90   4.98    24.0  \n",
       "1       17.8  396.90   9.14    21.6  \n",
       "2       17.8  392.83   4.03    34.7  \n",
       "3       18.7  394.63   2.94    33.4  \n",
       "4       18.7  396.90   5.33    36.2  \n",
       "..       ...     ...    ...     ...  \n",
       "501     21.0  391.99   9.67    22.4  \n",
       "502     21.0  396.90   9.08    20.6  \n",
       "503     21.0  396.90   5.64    23.9  \n",
       "504     21.0  393.45   6.48    22.0  \n",
       "505     21.0  396.90   7.88    11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 整理原始資料, 並進行EDA\n",
    "df_boston = pd.DataFrame(boston['data'], columns=boston['feature_names'])\n",
    "df_target = pd.DataFrame(boston['target'], columns=['target'])\n",
    "df = pd.concat([df_boston, df_target], axis=1)\n",
    "df  # 全為數值型資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_boston.isnull().sum()  #沒有缺值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT  \n",
       "count  506.000000  \n",
       "mean    12.653063  \n",
       "std      7.141062  \n",
       "min      1.730000  \n",
       "25%      6.950000  \n",
       "50%     11.360000  \n",
       "75%     16.955000  \n",
       "max     37.970000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_boston.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bdbfd54408>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_boston.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step2] Least Square Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此資料集為回歸問題, 故使用LinearRegression\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_boston, df_target, test_size=0.1, random_state=4)\n",
    "\n",
    "# 建立一個線性回歸模型\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "# 將訓練資料丟進去模型訓練\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# 將測試資料丟進模型得到預測結果\n",
    "y_pred = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coeficient :\n",
      "CRIM: -0.12585665878406954\n",
      "ZN: 0.0484257396100201\n",
      "INDUS: 0.01840852809252633\n",
      "CHAS: 3.085095691516899\n",
      "NOX: -17.327701820564606\n",
      "RM: 3.6167471330861467\n",
      "AGE: 0.0021918185271774765\n",
      "DIS: -1.4936113225001264\n",
      "RAD: 0.3199792000272681\n",
      "TAX: -0.01272946486141267\n",
      "PTRATIO: -0.927469085924641\n",
      "B: 0.009509124683760478\n",
      "LSTAT: -0.5335924706228666\n",
      "\n",
      "Mean squared error: 17.039\n"
     ]
    }
   ],
   "source": [
    "#各特徵係數\n",
    "print('coeficient :')\n",
    "\n",
    "for i, j in zip(df_boston.columns, reg.coef_[0]):\n",
    "    print(f'{i}: {j}')\n",
    "print()    \n",
    "# 預測值與實際值的差距，使用 MSE\n",
    "print(f\"Mean squared error: {round(mean_squared_error(y_test, y_pred), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step3] Lasso Regression (L1 norm.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_boston, df_target, test_size=0.1, random_state=4)\n",
    "\n",
    "# 建立一個線性回歸模型\n",
    "Lasso = linear_model.Lasso(alpha=2)\n",
    "\n",
    "# 將訓練資料丟進去模型訓練\n",
    "Lasso.fit(x_train, y_train)\n",
    "\n",
    "# 將測試資料丟進模型得到預測結果\n",
    "y_pred = Lasso.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coeficient :\n",
      "\n",
      "CRIM: -0.02373776827126448\n",
      "ZN: 0.03337257117417263\n",
      "INDUS: -0.0\n",
      "CHAS: 0.0\n",
      "NOX: -0.0\n",
      "RM: 0.0\n",
      "AGE: 0.04645090268516165\n",
      "DIS: -0.05385332233022369\n",
      "RAD: 0.17209628733167168\n",
      "TAX: -0.011660716114175698\n",
      "PTRATIO: -0.5564866826886662\n",
      "B: 0.007101118645512347\n",
      "LSTAT: -0.8213388039730934\n",
      "\n",
      "Feature deletion candidates: \n",
      " (features listed below are considered to be removed from the training data for better fitting of the model) \n",
      " ['INDUS', 'CHAS', 'NOX', 'RM']\n",
      "\n",
      "Mean squared error: 28.509\n"
     ]
    }
   ],
   "source": [
    "#各特徵係數\n",
    "print('coeficient :', end='\\n\\n')\n",
    "delete_list = []\n",
    "for i, j in zip(df_boston.columns, Lasso.coef_):\n",
    "    if j ==0:\n",
    "        delete_list.append(i)\n",
    "    print(f'{i}: {j}')\n",
    "print()\n",
    "print(f'Feature deletion candidates: \\n (features listed below are considered to be removed from the training data for better fitting of the model) \\n {delete_list}')\n",
    "print()\n",
    "\n",
    "# 預測值與實際值的差距，使用 MSE\n",
    "print(f\"Mean squared error: {round(mean_squared_error(y_test, y_pred), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coeficient :\n",
      "CRIM: -0.12056812160932537\n",
      "ZN: 0.07515226973959761\n",
      "AGE: 0.009812921056037264\n",
      "DIS: -1.3646340545387323\n",
      "RAD: 0.4047200581175486\n",
      "TAX: -0.020795341815980296\n",
      "PTRATIO: -0.9465659138822131\n",
      "B: 0.008470094887250857\n",
      "LSTAT: -0.8324425584628288\n",
      "\n",
      "Mean squared error: 24.455\n"
     ]
    }
   ],
   "source": [
    "# 驗證 L1 的 feature selection\n",
    "df_temp = df_boston.drop(['INDUS', 'CHAS', 'NOX', 'RM'], axis=1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_temp, df_target, test_size=0.1, random_state=4)\n",
    "reg2 = linear_model.LinearRegression()\n",
    "reg2.fit(x_train, y_train)\n",
    "y_pred = reg2.predict(x_test)\n",
    "\n",
    "#各特徵係數\n",
    "print('coeficient :')\n",
    "\n",
    "for i, j in zip(df_temp.columns, reg2.coef_[0]):\n",
    "    print(f'{i}: {j}')\n",
    "print()\n",
    "print(f\"Mean squared error: {round(mean_squared_error(y_test, y_pred), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step4] Ridge Regression (L2 norm.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_boston, df_target, test_size=0.1, random_state=4)\n",
    "\n",
    "# 建立一個線性回歸模型\n",
    "Rid = linear_model.Ridge(alpha=1)\n",
    "\n",
    "# 將訓練資料丟進去模型訓練\n",
    "Rid.fit(x_train, y_train)\n",
    "\n",
    "# 將測試資料丟進模型得到預測結果\n",
    "y_pred = Rid.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coeficient :\n",
      "\n",
      "CRIM: -0.12248803669322372\n",
      "ZN: 0.04954830487400808\n",
      "INDUS: -0.011583983289705637\n",
      "CHAS: 2.8907182033260583\n",
      "NOX: -10.040289498860082\n",
      "RM: 3.6667430619934596\n",
      "AGE: -0.00443653914589698\n",
      "DIS: -1.389908621735465\n",
      "RAD: 0.30228629158784265\n",
      "TAX: -0.013225979812376196\n",
      "PTRATIO: -0.8521417939742221\n",
      "B: 0.009867083531947405\n",
      "LSTAT: -0.5436811301680253\n",
      "\n",
      "Mean squared error: 17.352\n"
     ]
    }
   ],
   "source": [
    "#各特徵係數\n",
    "print('coeficient :' ,end='\\n\\n')\n",
    "\n",
    "for i, j in zip(df_boston.columns, Rid.coef_[0]):\n",
    "    print(f'{i}: {j}')\n",
    "\n",
    "print()\n",
    "# 預測值與實際值的差距，使用 MSE\n",
    "print(f\"Mean squared error: {round(mean_squared_error(y_test, y_pred), 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
