{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"D101-D103_HW_Final_Exam_part3_Model_Building.ipynb","private_outputs":true,"provenance":[{"file_id":"1NH9RCunWcCEe_J_dU8_NXAQIsd3GsYNr","timestamp":1614920805141},{"file_id":"1XRN314xxv7VQx3RskWnU_4_VFfdu3zzr","timestamp":1614857366950}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm","mount_file_id":"1btecg1DFIkbJ-BRDH8lrWpVrKhyfPUP3","authorship_tag":"ABX9TyN6BCTVCYhY4kBp16xvisgv"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fyPOGMDzMQx9"},"source":["## Data Reading"]},{"cell_type":"code","metadata":{"id":"AmQ2ACND0wLT"},"source":["import cv2\r\n","import os\r\n","import keras\r\n","import matplotlib.pyplot as plt\r\n","import pandas as pd\r\n","import numpy as np\r\n","from glob import glob\r\n","from tqdm.auto import tqdm\r\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OhLe7j8Q5oKM"},"source":["製作label"]},{"cell_type":"code","metadata":{"id":"QFywNLXB5nWO"},"source":["path = '/content/drive/MyDrive/ColabWorkBench/MLMarathon/Final_Exam/train'\r\n","names = os.listdir(path) # names = ['daisy', 'dandelion', 'tulip', 'rose', 'sunflower']\r\n","class_map = {'daisy':0, 'dandelion':1, 'rose':2, 'sunflower':3, 'tulip':4}\r\n","\r\n","# 製作一個空字典, 準備承接花名及數量資料\r\n","num_img = dict(zip(names,('','','','','')))\r\n","for name in names:\r\n","  tmp_path = os.path.join(path, name)\r\n","  img_list = glob(tmp_path+'/*.jpg')\r\n","  num_img[name] = len(img_list)\r\n","  print(f'{len(img_list)} images of {name}')\r\n","\r\n","# 利用pandas進行label製作及排序\r\n","label = []\r\n","for i in names:\r\n","  label += [i]*num_img[i]\r\n","\r\n","label = pd.DataFrame(label)\r\n","\r\n","# 將str轉為相對應數字編號, 以利後續模型訓練\r\n","label[0] = label[0].map(class_map) \r\n","\r\n","# map轉換後, 順序可能會不一樣, 故重新排序\r\n","label = label.sort_values(by=[0],ascending=True).reset_index(drop=True)\r\n","label = np.array(label)\r\n","\r\n","\r\n","# 轉為one-hot encoding\r\n","label_onehot = keras.utils.to_categorical(label, num_classes=5)\r\n","print('label: ',label_onehot[0:4,:])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b-GuBfOw7wlA"},"source":["讀入圖片並resize成128 x 128 ( w x h )"]},{"cell_type":"code","metadata":{"id":"pUZo9yUt7v6X"},"source":["path = '/content/drive/MyDrive/ColabWorkBench/MLMarathon/Final_Exam/train'\r\n","names = os.listdir(path) # names = ['daisy', 'dandelion', 'tulip', 'rose', 'sunflower']\r\n","\r\n","# 讀取各圖片實體位置, 並儲存於變數data\r\n","data = {}\r\n","img_paths = []\r\n","for name in names:\r\n","  tmp_list = []\r\n","  tmp_path = os.path.join(path, name)\r\n","  img_list = glob(tmp_path+'/*.jpg')\r\n","  data[name]=img_list\r\n","  img_paths.extend(data[name])\r\n","\r\n","data_count = len(img_paths)\r\n","print(f'total images: {data_count}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IJgA9gAJ7wCT"},"source":["\r\n","\r\n","# 定義一個讀取及轉換尺寸的func\r\n","def read_img(img_path, target_size=(128, 128)):\r\n","  img = cv2.imread(img_path)\r\n","  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n","  img = cv2.resize(img,target_size)\r\n","  return img\r\n","\r\n","\r\n","X = np.zeros((data_count, 128, 128, 3))\r\n","\r\n","# 讀取資料\r\n","for i, path in tqdm(enumerate(img_paths), total=len(img_paths)):\r\n","  X[i] = read_img(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E4LNvy6-7wIr"},"source":["# train/test split\r\n","x_train, x_test, y_train, y_test = train_test_split(X, label_onehot, test_size=0.15)\r\n","print(f'x_train shape: {x_train.shape}')\r\n","print(f'x_test shape: {x_test.shape}')\r\n","print(f'y_train shape: {y_train.shape}')\r\n","print(f'y_test shape: {y_test.shape}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dD58lzrges8z"},"source":["## Data Generator & Augmentation"]},{"cell_type":"code","metadata":{"id":"ug2oD0KwfIBP"},"source":["from keras.preprocessing.image import ImageDataGenerator"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HCKsWR9KfKzM"},"source":["datagen = ImageDataGenerator(        \r\n","        rotation_range=45,\r\n","        width_shift_range=0.2,\r\n","        height_shift_range=0.2,\r\n","        shear_range=0.5,\r\n","        \r\n","        vertical_flip=True,\r\n","        zoom_range=0.8,\r\n","        channel_shift_range=80,\r\n","                 \r\n","        horizontal_flip=True)\r\n","\r\n","\r\n","# rescale= 1.0/255 shear_range=0.6channel_shift_range=80,"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UYWphaRiT1N3"},"source":["## Model Building"]},{"cell_type":"code","metadata":{"id":"fWfRczZ_UJbp"},"source":["from keras.layers import Input, Dense, Flatten, BatchNormalization, Dropout\r\n","from keras.models import Model\r\n","from keras.callbacks import ReduceLROnPlateau\r\n","from keras import regularizers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MZfF7yjMDMxu"},"source":["datagen.fit(x_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tZw7r1TS4efx"},"source":["# keras.backend.clear_session()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p02FdGdH2hK_"},"source":["reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.75, patience=5, verbose=1, min_lr=1e-7 )\r\n","LR = 0.001\r\n","pen=0.00001\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UeTMN1QMehox"},"source":["base_model = keras.applications.Xception(include_top=False, weights='imagenet', input_shape=(128, 128, 3),pooling='max' ) # weights='imagenet'\r\n","x = base_model.output\r\n","x = Flatten()(x)\r\n","x = Dense(1024, activation='relu',kernel_regularizer=regularizers.l2(pen))(x)\r\n","x = BatchNormalization()(x)\r\n","x = Dropout(0.7)(x)\r\n","x = Dense(1024, activation='relu', kernel_regularizer=regularizers.l2(pen))(x)\r\n","x = BatchNormalization()(x)\r\n","x = Dropout(0.5)(x)\r\n","x = Dense(512, activation='relu', )(x)\r\n","x = BatchNormalization()(x)\r\n","x = Dropout(0.3)(x)\r\n","\r\n","\r\n","predictions = Dense(5, activation='softmax')(x)\r\n","model = Model(base_model.input, predictions)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BUkATz8fUvOA"},"source":["## Model Training"]},{"cell_type":"code","metadata":{"id":"qiSCdKojbmdL"},"source":["model.compile(loss=keras.losses.categorical_crossentropy,\r\n","              optimizer=keras.optimizers.Adam(lr=LR),\r\n","              metrics=['accuracy'])\r\n","\r\n","\r\n","\r\n","logs = model.fit(datagen.flow(x_train, y_train, batch_size=256),\r\n","          steps_per_epoch=x_train.shape[0]//256,\r\n","          epochs=80,\r\n","          verbose=1,\r\n","          callbacks=[reduce_lr],\r\n","          shuffle=True,    \r\n","          validation_data=(x_test, y_test),\r\n","          )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VbT4Ve7RVfxV"},"source":["history = logs.history\r\n","plt.plot(history['accuracy'])\r\n","plt.plot(history['val_accuracy'])\r\n","plt.legend(['acc', 'val_accuracy'])\r\n","plt.title('Accuracy')\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KhiNIoAdVtlh"},"source":["plt.plot(history['loss'])\r\n","plt.plot(history['val_loss'])\r\n","plt.legend(['loss', 'val_loss'])\r\n","plt.title('Loss')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9YxV8craEDXl"},"source":["## model prediction"]},{"cell_type":"code","metadata":{"id":"LQd-WgPZomxG"},"source":["path = '/content/drive/MyDrive/ColabWorkBench/MLMarathon/Final_Exam/test'\r\n","\r\n","\r\n","# 讀取各圖片實體位置\r\n","\r\n","img_list = glob(path+'/*.jpg')\r\n","\r\n","total_test_img_count = len(img_list)\r\n","print(f'total test images: {total_test_img_count}')\r\n","\r\n","# 以id_list儲存個圖片id\r\n","id_list = [img_list[x].replace('.jpg','').split('/')[-1] for x in range(len(img_list))]\r\n","id_list[0:5]\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DnROeIaheQ0v"},"source":["img_list[0:5]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rsGLfyGgDlFu"},"source":["# 讀取測試集圖片\r\n","X_test = np.zeros((total_test_img_count, 128, 128, 3))\r\n","for i, path in tqdm(enumerate(img_list), total=len(img_list)):\r\n","  X_test[i] = read_img(path) # read & resize to target pixels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QDTEEAQGVov0"},"source":["X_test.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-lNixpHTC9a6"},"source":["# model prediction\r\n","\r\n","pred = model.predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iozifba0LE9I"},"source":["pred.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B6uMuRwnWPoW"},"source":["pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6UQYPW_iLFAP"},"source":["d = np.argmax(pred, axis=1)\r\n","d.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MScf0vBCLFDN"},"source":["print(d[:5])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IHzWRBu5L7a5"},"source":["ans = pd.DataFrame({'id':id_list,'flower_class':d})\r\n","ans"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8LCTmBKoOgTF"},"source":["ans.to_csv('/content/drive/MyDrive/ColabWorkBench/MLMarathon/Final_Exam/0309_out2.csv', index=False)"],"execution_count":null,"outputs":[]}]}